{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df615c54",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089167f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Entorno:\n",
      "  MLFLOW_TRACKING_URI: None\n",
      "  DATABRICKS_CONFIG_PROFILE: None\n",
      "  DATABRICKS_HOST: https://dbc-5922e233-b716.cloud.databricks.com/\n",
      "  DATABRICKS_TOKEN set?: True\n",
      "üîó MLflow tracking URI: databricks\n",
      "   DATABRICKS_CONFIG_PROFILE: None\n",
      "   DATABRICKS_HOST set?: True\n",
      "   DATABRICKS_TOKEN set?: True\n",
      "‚úÖ Experimento encontrado: /Users/marianasgg19@gmail.com/EMI/imedia/experiment (id=2410509746257126)\n",
      "üîó MLflow registry URI: databricks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/24 01:47:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/24 01:47:14 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/11/24 01:47:14 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run elasticnet_trial at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126/runs/5bf089dbd97c4ebaafb4ce6e45b39d3b\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/24 01:47:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/24 01:47:19 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run elasticnet_trial at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126/runs/f2432ed67b274690aaeb42384baf73ea\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/24 01:47:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/24 01:47:25 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run elasticnet_trial at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126/runs/9773690648de4c4a980f833b0ec202e1\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/24 01:47:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/24 01:47:29 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run HPO_elasticnet at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126/runs/92e9a8549e664489a9c54329aebc5f2b\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/24 01:47:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/24 01:47:34 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run random_forest_trial at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126/runs/f59018912f464c3b8133f8a0f5f335ed\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/24 01:47:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/24 01:47:43 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run random_forest_trial at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126/runs/f116654b304e482b84d424615f1d2c1b\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/24 01:47:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/24 01:47:52 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run random_forest_trial at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126/runs/b772f4e38c3d43a0be9093f3dd6cc7ee\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/24 01:47:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/24 01:47:58 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run HPO_random_forest at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126/runs/e42c7e6ba363438cb511eb4141527ca9\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/24 01:48:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/24 01:48:08 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run xgboost_trial at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126/runs/e6997ded03274bccac6a1e8aa9199c04\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/24 01:48:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/24 01:48:14 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run xgboost_trial at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126/runs/6d678312f49d496697cab0a25c9e6dee\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/24 01:48:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/24 01:48:20 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run xgboost_trial at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126/runs/21fd11f96b224deb9fe3880806680012\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/24 01:48:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/24 01:48:27 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run HPO_xgboost at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126/runs/cd3982fea75a43b8a86ec4119bed2b7a\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126\n",
      "üèÉ View run IMEDIA_EMI_AllModels at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126/runs/16fd3e23ed6545b3a41ed43418323f19\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126\n",
      "=== Resultados por modelo (ordenados por RMSE asc) ===\n",
      "       model_key                        parent_run  \\\n",
      "0  random_forest  e42c7e6ba363438cb511eb4141527ca9   \n",
      "1        xgboost  cd3982fea75a43b8a86ec4119bed2b7a   \n",
      "2     elasticnet  92e9a8549e664489a9c54329aebc5f2b   \n",
      "\n",
      "                                         best_params    val_rmse  \n",
      "0  {'max_depth': 19, 'max_features': None, 'min_s...   95.584186  \n",
      "1  {'colsample_bytree': 0.7295996142861736, 'lear...   98.757263  \n",
      "2  {'alpha': 0.12606513359349072, 'l1_ratio': 0.8...  131.634897  \n",
      "üîó MLflow tracking URI: databricks\n",
      "   DATABRICKS_CONFIG_PROFILE: None\n",
      "   DATABRICKS_HOST set?: True\n",
      "   DATABRICKS_TOKEN set?: True\n",
      "‚úÖ Experimento encontrado: /Users/marianasgg19@gmail.com/EMI/imedia/experiment (id=2410509746257126)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/24 01:48:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/24 01:48:34 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/11/24 01:48:40 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/24 01:48:40 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/11/24 01:48:42 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/24 01:48:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/11/24 01:48:43 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/11/24 01:48:44 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Preprocesador guardado localmente en: /Users/msgarcia/Desktop/School/proyecto_2/IMEDIA_Project_v2/preprocesador/random_forest_preprocessor_20251124_074843\n",
      "üèÉ View run FINAL_random_forest_on_full_train at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126/runs/d44c2e77ac0f4a28a9d8d0ec9618c9d1\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126\n",
      "üîó MLflow registry URI: databricks-uc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'workspace.default.EMI_imedia_model' already exists. Creating a new version of this model...\n",
      "2025/11/24 01:48:46 WARNING mlflow.tracking._model_registry.fluent: Run with id d44c2e77ac0f4a28a9d8d0ec9618c9d1 has no artifacts at artifact path 'model', registering model based on models:/m-30b760377fc540c98e0c0bb199e071bf instead\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.37it/s]\n",
      "Uploading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.06it/s]\n",
      "Created version '5' of model 'workspace.default.emi_imedia_model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó MLflow tracking URI: databricks\n",
      "   DATABRICKS_CONFIG_PROFILE: None\n",
      "   DATABRICKS_HOST set?: True\n",
      "   DATABRICKS_TOKEN set?: True\n",
      "‚úÖ Experimento encontrado: /Users/marianasgg19@gmail.com/EMI/imedia/experiment (id=2410509746257126)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/24 01:49:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/24 01:49:03 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/11/24 01:49:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/24 01:49:07 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/11/24 01:49:08 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/24 01:49:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/11/24 01:49:09 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/11/24 01:49:10 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Registered model 'workspace.default.EMI_imedia_model' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Preprocesador (challenger) guardado localmente en: /Users/msgarcia/Desktop/School/proyecto_2/IMEDIA_Project_v2/preprocesador/xgboost_preprocessor_20251124_074909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/24 01:49:11 WARNING mlflow.tracking._model_registry.fluent: Run with id 285dd5ccabe5424282bc23d015a5a0ad has no artifacts at artifact path 'model', registering model based on models:/m-abbbe4cc76604be5bc206294627828af instead\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  4.03it/s]\n",
      "Uploading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.55it/s]\n",
      "Created version '6' of model 'workspace.default.emi_imedia_model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run FINAL_xgboost_challenger at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126/runs/285dd5ccabe5424282bc23d015a5a0ad\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126\n",
      "\n",
      "‚úÖ Registro completo en Model Registry (Unity Catalog)\n",
      "  Champion  -> workspace.default.EMI_imedia_model@champion (v5)\n",
      "  Challenger -> workspace.default.EMI_imedia_model@challenger (v6)\n",
      "\n",
      "Experimento MLflow: /Users/marianasgg19@gmail.com/EMI/imedia/experiment\n",
      "M√©trica √∫nica de selecci√≥n: RMSE (menor es mejor)\n",
      "Target: score_clipped\n",
      "Features: ['num_comments_capped', 'recency_days', 'dayofweek', 'title_len', 'selftext_len', 'is_self', 'month', 'link_flair_text', 'subreddit', 'author']\n",
      "Train shape: (1233, 11) | Test shape: (309, 11)\n",
      "\n",
      "=== Tabla comparativa RMSE (menor es mejor) ===\n",
      "       model_key split        rmse\n",
      "0  random_forest  test   84.697971\n",
      "1        xgboost  test   85.303490\n",
      "2  random_forest   val   95.584186\n",
      "3        xgboost   val   98.757263\n",
      "4     elasticnet   val  131.634897\n",
      "\n",
      "üìÑ Tabla comparativa guardada en: /Users/msgarcia/Desktop/School/proyecto_2/IMEDIA_Project_v2/notebooks/model_metric_comparison.csv\n",
      "üîó MLflow tracking URI: databricks\n",
      "   DATABRICKS_CONFIG_PROFILE: None\n",
      "   DATABRICKS_HOST set?: True\n",
      "   DATABRICKS_TOKEN set?: True\n",
      "‚úÖ Experimento encontrado: /Users/marianasgg19@gmail.com/EMI/imedia/experiment (id=2410509746257126)\n",
      "üèÉ View run METRICS_COMPARISON at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126/runs/6a03021ac37c4b6398197a131f4e596b\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/2410509746257126\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# IMEDIA ¬∑ Equipo EMI ¬∑ Training + HPO + Registry (Hyperopt + MLflow)\n",
    "# Auto-resoluci√≥n de tracking (Databricks si hay auth; local si no)\n",
    "# ============================================================\n",
    "import os, sys, json, math, time, hashlib, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ML/Preproc\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Hyperopt\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# .env\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# -------------------------------\n",
    "# Configuraci√≥n base / Reproducibilidad\n",
    "# -------------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "EXPERIMENT_NAME = \"/Users/marianasgg19@gmail.com/EMI/imedia/experiment\"   # <-- ajusta si deseas\n",
    "MODEL_NAME = \"workspace.default/EMI_imedia_model\"                         # nomenclatura sugerida\n",
    "\n",
    "# >>> : carpeta local para guardar el preprocesador\n",
    "PREPROC_LOCAL_DIR = Path(\"../preprocesador\")\n",
    "PREPROC_LOCAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "# <<< \n",
    "\n",
    "# -------------------------------\n",
    "# Carga datasets preparados\n",
    "# -------------------------------\n",
    "data_dir = Path(\"../data/processed\")\n",
    "train_csv = data_dir / \"train_posts_clean.csv\"\n",
    "test_csv  = data_dir / \"test_posts_clean.csv\"\n",
    "\n",
    "assert train_csv.exists(), f\"No existe {train_csv}\"\n",
    "assert test_csv.exists(),  f\"No existe {test_csv}\"\n",
    "\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df  = pd.read_csv(test_csv)\n",
    "\n",
    "# -------------------------------\n",
    "# Metadatos de datasets (versionado b√°sico)\n",
    "# -------------------------------\n",
    "def file_md5(path: Path) -> str:\n",
    "    h = hashlib.md5()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "train_meta = {\"path\": str(train_csv), \"shape\": list(train_df.shape), \"md5\": file_md5(train_csv)}\n",
    "test_meta  = {\"path\": str(test_csv),  \"shape\": list(test_df.shape),  \"md5\": file_md5(test_csv)}\n",
    "\n",
    "# -------------------------------\n",
    "# Definici√≥n de columnas y target\n",
    "# -------------------------------\n",
    "TARGET = \"score_clipped\" if \"score_clipped\" in train_df.columns else \"score\"\n",
    "\n",
    "# Toma tus features seleccionadas y filtra por existencia\n",
    "CANDIDATE_FEATURES = [\n",
    "    'num_comments_capped',\n",
    "    'recency_days',\n",
    "    'dayofweek',\n",
    "    'title_len',\n",
    "    'selftext_len',\n",
    "    'is_self',\n",
    "    'month',\n",
    "    'link_flair_text',\n",
    "    'subreddit',\n",
    "    'author'\n",
    "]\n",
    "FEATURES = [c for c in CANDIDATE_FEATURES if c in train_df.columns]\n",
    "\n",
    "# Separaci√≥n de tipos\n",
    "cat_cols = [c for c in FEATURES if train_df[c].dtype == \"object\"]\n",
    "num_cols = [c for c in FEATURES if c not in cat_cols]\n",
    "\n",
    "# -------------------------------\n",
    "# Preprocesador (integrado en cada pipeline)\n",
    "# -------------------------------\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=True, with_std=True), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", min_frequency=5), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Split interno train/val (para HPO)\n",
    "# -------------------------------\n",
    "X = train_df[FEATURES].copy()\n",
    "y = train_df[TARGET].astype(float).copy()\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, shuffle=True\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Espacios de b√∫squeda (Hyperopt)\n",
    "# -------------------------------\n",
    "spaces = {\n",
    "    \"elasticnet\": {\n",
    "        \"alpha\": hp.loguniform(\"alpha\", math.log(1e-4), math.log(10.0)),\n",
    "        \"l1_ratio\": hp.uniform(\"l1_ratio\", 0.0, 1.0),\n",
    "    },\n",
    "    \"random_forest\": {\n",
    "        \"n_estimators\": hp.quniform(\"n_estimators\", 100, 1000, 50),\n",
    "        \"max_depth\": hp.quniform(\"max_depth\", 4, 30, 1),\n",
    "        \"min_samples_split\": hp.quniform(\"min_samples_split\", 2, 20, 1),\n",
    "        \"min_samples_leaf\": hp.quniform(\"min_samples_leaf\", 1, 10, 1),\n",
    "        \"max_features\": hp.choice(\"max_features\", [\"sqrt\", \"log2\", None]),\n",
    "    },\n",
    "    \"xgboost\": {\n",
    "        \"n_estimators\": hp.quniform(\"n_estimators\", 200, 1200, 50),\n",
    "        \"max_depth\": hp.quniform(\"max_depth\", 3, 12, 1),\n",
    "        \"learning_rate\": hp.loguniform(\"learning_rate\", math.log(1e-3), math.log(0.3)),\n",
    "        \"subsample\": hp.uniform(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_alpha\": hp.loguniform(\"reg_alpha\", math.log(1e-8), math.log(1e-1)),\n",
    "        \"reg_lambda\": hp.loguniform(\"reg_lambda\", math.log(1e-6), math.log(1.0)),\n",
    "        \"min_child_weight\": hp.quniform(\"min_child_weight\", 1, 10, 1),\n",
    "    },\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# Helpers MLflow: tracking resiliente + tags seguros\n",
    "# -------------------------------\n",
    "def _resolve_tracking_uri() -> str:\n",
    "    \"\"\"\n",
    "    Prioriza .env / entorno; si no hay auth Databricks, usa tracking local en ./mlruns.\n",
    "    \"\"\"\n",
    "    load_dotenv(override=True)\n",
    "    env_uri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "    profile = os.getenv(\"DATABRICKS_CONFIG_PROFILE\")\n",
    "    host = os.getenv(\"DATABRICKS_HOST\")\n",
    "    token = os.getenv(\"DATABRICKS_TOKEN\")\n",
    "\n",
    "    if env_uri:  # respeta configuraci√≥n expl√≠cita\n",
    "        return env_uri\n",
    "    if profile:  # databricks via perfil\n",
    "        return f\"databricks://{profile}\"\n",
    "    if host and token:  # databricks via host+token\n",
    "        return \"databricks\"\n",
    "\n",
    "    # Fallback local\n",
    "    local_store = Path.cwd() / \"mlruns\"\n",
    "    local_store.mkdir(parents=True, exist_ok=True)\n",
    "    return f\"file://{local_store}\"\n",
    "\n",
    "def set_mlflow():\n",
    "    tracking_uri = _resolve_tracking_uri()\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "    # Diagn√≥stico √∫til\n",
    "    print(f\"üîó MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "    print(\"   DATABRICKS_CONFIG_PROFILE:\", os.getenv(\"DATABRICKS_CONFIG_PROFILE\"))\n",
    "    print(\"   DATABRICKS_HOST set?:\", bool(os.getenv(\"DATABRICKS_HOST\")))\n",
    "    print(\"   DATABRICKS_TOKEN set?:\", bool(os.getenv(\"DATABRICKS_TOKEN\")))\n",
    "\n",
    "    # Asegurar experimento\n",
    "    client = MlflowClient()\n",
    "    exp = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if exp is None:\n",
    "        exp_id = client.create_experiment(EXPERIMENT_NAME)\n",
    "        print(f\"üÜï Experimento creado: {EXPERIMENT_NAME} (id={exp_id})\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Experimento encontrado: {EXPERIMENT_NAME} (id={exp.experiment_id})\")\n",
    "\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "def log_dataset_meta(prefix: str):\n",
    "    mlflow.log_dict(train_meta, f\"{prefix}_train_meta.json\")\n",
    "    mlflow.log_dict(test_meta,  f\"{prefix}_test_meta.json\")\n",
    "\n",
    "def str_tags(d: dict) -> dict:\n",
    "    \"\"\"Convierte cualquier valor a string para tags (MLflow exige str).\"\"\"\n",
    "    return {str(k): (json.dumps(v) if isinstance(v, (dict, list)) else str(v)) for k, v in d.items()}\n",
    "\n",
    "# -------------------------------\n",
    "# Definiciones de modelos y objetivos HPO\n",
    "# -------------------------------\n",
    "def build_pipeline(model_key, params):\n",
    "    if model_key == \"elasticnet\":\n",
    "        model = ElasticNet(\n",
    "            alpha=float(params[\"alpha\"]),\n",
    "            l1_ratio=float(params[\"l1_ratio\"]),\n",
    "            random_state=SEED,\n",
    "            max_iter=10000\n",
    "        )\n",
    "    elif model_key == \"random_forest\":\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=int(params[\"n_estimators\"]),\n",
    "            max_depth=int(params[\"max_depth\"]),\n",
    "            min_samples_split=int(params[\"min_samples_split\"]),\n",
    "            min_samples_leaf=int(params[\"min_samples_leaf\"]),\n",
    "            max_features=params[\"max_features\"],  # None / 'sqrt' / 'log2'\n",
    "            n_jobs=-1,\n",
    "            random_state=SEED\n",
    "        )\n",
    "    elif model_key == \"xgboost\":\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=int(params[\"n_estimators\"]),\n",
    "            max_depth=int(params[\"max_depth\"]),\n",
    "            learning_rate=float(params[\"learning_rate\"]),\n",
    "            subsample=float(params[\"subsample\"]),\n",
    "            colsample_bytree=float(params[\"colsample_bytree\"]),\n",
    "            reg_alpha=float(params[\"reg_alpha\"]),\n",
    "            reg_lambda=float(params[\"reg_lambda\"]),\n",
    "            min_child_weight=int(params[\"min_child_weight\"]),\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=SEED,\n",
    "            n_jobs=-1,\n",
    "            tree_method=\"hist\",\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Modelo no soportado\")\n",
    "\n",
    "    pipe = Pipeline(steps=[(\"prep\", preprocessor), (\"model\", model)])\n",
    "    return pipe\n",
    "\n",
    "def make_objective(model_key):\n",
    "    def _objective(params):\n",
    "        with mlflow.start_run(run_name=f\"{model_key}_trial\", nested=True) as run:\n",
    "            # construir pipeline y entrenar\n",
    "            pipe = build_pipeline(model_key, params)\n",
    "            pipe.fit(X_tr, y_tr)\n",
    "\n",
    "            # evaluar\n",
    "            y_pred = pipe.predict(X_val)\n",
    "            metric = rmse(y_val, y_pred)\n",
    "\n",
    "            # log params/metric/artifacts\n",
    "            mlflow.set_tag(\"team\", \"EMI\")\n",
    "            mlflow.set_tag(\"project\", \"imedia\")\n",
    "            mlflow.set_tag(\"model_family\", model_key)\n",
    "            mlflow.set_tag(\"feature_set\", json.dumps(FEATURES))\n",
    "            mlflow.log_metric(\"rmse\", float(metric))\n",
    "            mlflow.log_params({\n",
    "                k: (float(v) if isinstance(v, (np.floating,)) else (int(v) if isinstance(v, (np.integer,)) else v))\n",
    "                for k, v in params.items()\n",
    "            })\n",
    "            # signature e input_example (peque√±o)\n",
    "            x_example = X_val.head(5).copy()\n",
    "            y_example = pipe.predict(x_example)\n",
    "            signature = infer_signature(x_example, y_example)\n",
    "            mlflow.sklearn.log_model(\n",
    "                sk_model=pipe,\n",
    "                artifact_path=\"model\",\n",
    "                signature=signature,\n",
    "                input_example=x_example\n",
    "            )\n",
    "            # datasets meta\n",
    "            log_dataset_meta(prefix=f\"{model_key}\")\n",
    "            # Devolver p√©rdida para Hyperopt (minimizar)\n",
    "            return {\"loss\": float(metric), \"status\": STATUS_OK, \"run_id\": run.info.run_id}\n",
    "    return _objective\n",
    "\n",
    "# -------------------------------\n",
    "# Entrenar/HPO por modelo (3 modelos)\n",
    "# -------------------------------\n",
    "print(\"üì¶ Entorno:\")\n",
    "print(\"  MLFLOW_TRACKING_URI:\", os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "print(\"  DATABRICKS_CONFIG_PROFILE:\", os.getenv(\"DATABRICKS_CONFIG_PROFILE\"))\n",
    "print(\"  DATABRICKS_HOST:\", os.getenv(\"DATABRICKS_HOST\"))\n",
    "print(\"  DATABRICKS_TOKEN set?:\", bool(os.getenv(\"DATABRICKS_TOKEN\")))\n",
    "\n",
    "# rmse seguro (sin 'squared')\n",
    "def rmse(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "# RNG compatible con Hyperopt (.integers)\n",
    "def make_rstate(seed: int):\n",
    "    return np.random.default_rng(seed)\n",
    "\n",
    "# üëâ Tracking + Experiment\n",
    "set_mlflow()\n",
    "\n",
    "# üëâ Forzar Model Registry \"legacy\" (Workspace), NO Unity Catalog\n",
    "mlflow.set_registry_uri(\"databricks\")\n",
    "print(\"üîó MLflow registry URI:\", mlflow.get_registry_uri())\n",
    "\n",
    "results_summary = []  # para documentar todo y luego elegir campe√≥n/desafiante\n",
    "\n",
    "MODELS = [\n",
    "    (\"elasticnet\", spaces[\"elasticnet\"], 3),     \n",
    "    (\"random_forest\", spaces[\"random_forest\"], 3),\n",
    "    (\"xgboost\", spaces[\"xgboost\"], 3),\n",
    "]\n",
    "\n",
    "with mlflow.start_run(\n",
    "    run_name=\"IMEDIA_EMI_AllModels\",\n",
    "    tags=str_tags({\n",
    "        \"team\": \"EMI\",\n",
    "        \"project\": \"imedia\",\n",
    "        \"target\": TARGET,\n",
    "        \"metric\": \"rmse\",\n",
    "        \"seed\": SEED,\n",
    "        \"preprocessor\": \"ColumnTransformer(StandardScaler + OneHotEncoder)\",\n",
    "        \"preprocessor_in_pipeline\": True\n",
    "    })\n",
    ") as parent_run:\n",
    "\n",
    "    parent_run_id = parent_run.info.run_id\n",
    "    mlflow.log_text(\n",
    "        f\"Datasets:\\ntrain={train_meta}\\ntest={test_meta}\\n\"\n",
    "        f\"Features={FEATURES}\\nTarget={TARGET}\\nSeed={SEED}\\nDate={datetime.utcnow().isoformat()}Z\",\n",
    "        \"run_context.txt\"\n",
    "    )\n",
    "\n",
    "    for model_key, space, n_trials in MODELS:\n",
    "        trials = Trials()\n",
    "        with mlflow.start_run(run_name=f\"HPO_{model_key}\", nested=True) as model_parent:\n",
    "            model_parent_id = model_parent.info.run_id\n",
    "            objective = make_objective(model_key)\n",
    "\n",
    "            # Hyperopt espera RNG con .integers -> default_rng\n",
    "            best = fmin(\n",
    "                fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=n_trials,\n",
    "                rstate=make_rstate(SEED),\n",
    "                show_progressbar=False\n",
    "            )\n",
    "\n",
    "            # Tipos/valores correctos para mejores params\n",
    "            if model_key == \"random_forest\":\n",
    "                best[\"n_estimators\"] = int(best[\"n_estimators\"])\n",
    "                best[\"max_depth\"] = int(best[\"max_depth\"])\n",
    "                best[\"min_samples_split\"] = int(best[\"min_samples_split\"])\n",
    "                best[\"min_samples_leaf\"] = int(best[\"min_samples_leaf\"])\n",
    "                # hp.choice devuelve √≠ndice -> mapear al valor real\n",
    "                max_feats_choices = [\"sqrt\", \"log2\", None]\n",
    "                if isinstance(best.get(\"max_features\"), (int, np.integer)):\n",
    "                    best[\"max_features\"] = max_feats_choices[int(best[\"max_features\"])]\n",
    "\n",
    "            if model_key == \"xgboost\":\n",
    "                best[\"n_estimators\"] = int(best[\"n_estimators\"])\n",
    "                best[\"max_depth\"] = int(best[\"max_depth\"])\n",
    "                best[\"min_child_weight\"] = int(best[\"min_child_weight\"])\n",
    "\n",
    "            mlflow.log_params({f\"best_{model_key}_{k}\": v for k, v in best.items()})\n",
    "\n",
    "            # Re-entrenar con mejores params en train (X_tr) y evaluar en val\n",
    "            pipe_best = build_pipeline(model_key, best)\n",
    "            pipe_best.fit(X_tr, y_tr)\n",
    "            val_rmse = rmse(y_val, pipe_best.predict(X_val))\n",
    "            mlflow.log_metric(\"val_rmse_best\", float(val_rmse))\n",
    "\n",
    "            # Snapshot del mejor de HPO\n",
    "            x_example = X_val.head(5)\n",
    "            y_example = pipe_best.predict(x_example)\n",
    "            sig = infer_signature(x_example, y_example)\n",
    "            mlflow.sklearn.log_model(\n",
    "                pipe_best,\n",
    "                artifact_path=f\"{model_key}_best_snapshot\",\n",
    "                signature=sig,\n",
    "                input_example=x_example\n",
    "            )\n",
    "\n",
    "            results_summary.append({\n",
    "                \"model_key\": model_key,\n",
    "                \"parent_run\": model_parent_id,\n",
    "                \"best_params\": best,\n",
    "                \"val_rmse\": float(val_rmse)\n",
    "            })\n",
    "\n",
    "# -------------------------------\n",
    "# Selecci√≥n expl√≠cita por RMSE (m√©trica √∫nica)\n",
    "# -------------------------------\n",
    "results_df = pd.DataFrame(results_summary).sort_values(\"val_rmse\", ascending=True).reset_index(drop=True)\n",
    "print(\"=== Resultados por modelo (ordenados por RMSE asc) ===\")\n",
    "print(results_df)\n",
    "\n",
    "best_model_key = results_df.loc[0, \"model_key\"]\n",
    "second_model_key = results_df.loc[1, \"model_key\"] if len(results_df) > 1 else None\n",
    "best_params = results_df.loc[0, \"best_params\"]\n",
    "\n",
    "# -------------------------------\n",
    "# Entrenar modelo FINAL (mejor) sobre TODO el train_df y evaluar en test_df\n",
    "# -------------------------------\n",
    "X_train_full = train_df[FEATURES].copy()\n",
    "y_train_full = train_df[TARGET].astype(float).copy()\n",
    "X_test = test_df[FEATURES].copy()\n",
    "y_test = test_df[TARGET].astype(float).copy()\n",
    "\n",
    "final_pipe = build_pipeline(best_model_key, best_params)\n",
    "\n",
    "# (re)asegurar tracking y registry\n",
    "set_mlflow()\n",
    "mlflow.set_registry_uri(\"databricks\")\n",
    "\n",
    "best_test_rmse = None  # <-- para tabla comparativa\n",
    "\n",
    "with mlflow.start_run(\n",
    "    run_name=f\"FINAL_{best_model_key}_on_full_train\",\n",
    "    tags=str_tags({\n",
    "        \"team\": \"EMI\",\n",
    "        \"project\": \"imedia\",\n",
    "        \"stage\": \"final_fit\",\n",
    "        \"selected_by\": \"rmse ASC\",\n",
    "        \"seed\": SEED\n",
    "    })\n",
    ") as final_run:\n",
    "    final_pipe.fit(X_train_full, y_train_full)\n",
    "    test_pred = final_pipe.predict(X_test)\n",
    "    test_rmse = rmse(y_test, test_pred)\n",
    "    best_test_rmse = float(test_rmse)\n",
    "    mlflow.log_metric(\"test_rmse\", best_test_rmse)\n",
    "    mlflow.log_params({f\"final_{best_model_key}_{k}\": v for k, v in best_params.items()})\n",
    "    mlflow.set_tag(\"final_model_family\", best_model_key)\n",
    "    mlflow.set_tag(\"metric_selection\", \"rmse ASC (lower is better)\")\n",
    "    mlflow.set_tag(\"preprocessor_in_pipeline\", \"true\")\n",
    "\n",
    "    # Firma e input example\n",
    "    x_example = X_test.head(5)\n",
    "    y_example = final_pipe.predict(x_example)\n",
    "    signature = infer_signature(x_example, y_example)\n",
    "\n",
    "    # Registrar el pipeline completo (incluye preprocessor) en MLflow\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=final_pipe,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=x_example\n",
    "    )\n",
    "\n",
    "    # >>> >>> Registrar expl√≠citamente el PREPROCESADOR en MLflow **y guardarlo localmente en ./preprocesador/**\n",
    "    fitted_preprocessor = final_pipe.named_steps[\"prep\"]\n",
    "\n",
    "    # a) Como artifact MLflow (consistencia con tracking)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=fitted_preprocessor,\n",
    "        artifact_path=\"preprocessor\"\n",
    "    )\n",
    "\n",
    "    # b) Guardado LOCAL estilo MLflow (directorio con MLmodel + pickles) dentro de ./preprocesador/\n",
    "    ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    local_save_dir = PREPROC_LOCAL_DIR / f\"{best_model_key}_preprocessor_{ts}\"\n",
    "    mlflow.sklearn.save_model(sk_model=fitted_preprocessor, path=str(local_save_dir))\n",
    "    print(f\"üíæ Preprocesador guardado localmente en: {local_save_dir.resolve()}\")\n",
    "    # <<< <<<\n",
    "\n",
    "    # Descripci√≥n del modelo (para el registry)\n",
    "    model_description = {\n",
    "        \"team\": \"EMI\",\n",
    "        \"project\": \"imedia\",\n",
    "        \"target\": TARGET,\n",
    "        \"primary_metric\": \"rmse\",\n",
    "        \"test_rmse\": best_test_rmse,\n",
    "        \"features\": FEATURES,\n",
    "        \"preprocessor\": \"ColumnTransformer(StandardScaler + OneHotEncoder)\",\n",
    "        \"preprocessor_in_pipeline\": True,\n",
    "        \"datasets\": {\"train\": train_meta, \"test\": test_meta},\n",
    "        \"date\": datetime.utcnow().strftime(\"%Y-%m-%d\"),\n",
    "        \"seeds\": {\"global\": SEED, \"models\": SEED, \"hyperopt\": SEED},\n",
    "        \"changelog\": \"Registro autom√°tico con HPO (Hyperopt) para 3 familias; selecci√≥n por RMSE m√≠nimo.\",\n",
    "        \"responsibles\": [\"Equipo EMI\"]\n",
    "    }\n",
    "    mlflow.log_text(json.dumps(model_description, indent=2), \"model_description.json\")\n",
    "\n",
    "    best_run_id = final_run.info.run_id\n",
    "    best_run_uri = f\"runs:/{best_run_id}/model\"\n",
    "\n",
    "# -------------------------------\n",
    "# Registrar en Model Registry (Unity Catalog)\n",
    "# -------------------------------\n",
    "# Usa Unity Catalog como backend del Model Registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "print(\"üîó MLflow registry URI:\", mlflow.get_registry_uri())\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Nombre UC en formato catalog.schema.model\n",
    "MODEL_NAME_REG = \"workspace.default.EMI_imedia_model\"  # <= ajusta cat√°logo/esquema si usas otros\n",
    "\n",
    "# Registra el campe√≥n (el modelo final ya logueado en este run)\n",
    "result = mlflow.register_model(model_uri=best_run_uri, name=MODEL_NAME_REG)\n",
    "champ_version = result.version\n",
    "\n",
    "# Challenger opcional: segundo mejor (si existe)\n",
    "challenger_version = None\n",
    "challenger_test_rmse = None  # <-- para tabla comparativa\n",
    "if second_model_key is not None:\n",
    "    second_params = results_df.loc[1, \"best_params\"]\n",
    "    second_pipe = build_pipeline(second_model_key, second_params)\n",
    "\n",
    "    set_mlflow()  # asegura tracking para este nuevo run\n",
    "    mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "    with mlflow.start_run(\n",
    "        run_name=f\"FINAL_{second_model_key}_challenger\",\n",
    "        tags=str_tags({\n",
    "            \"team\": \"EMI\",\n",
    "            \"project\": \"imedia\",\n",
    "            \"stage\": \"final_fit_challenger\",\n",
    "            \"selected_by\": \"second_best_val_rmse\",\n",
    "            \"seed\": SEED\n",
    "        })\n",
    "    ) as chal_run:\n",
    "        second_pipe.fit(X_train_full, y_train_full)\n",
    "        chal_pred = second_pipe.predict(X_test)\n",
    "        chal_rmse = rmse(y_test, chal_pred)\n",
    "        challenger_test_rmse = float(chal_rmse)\n",
    "        mlflow.log_metric(\"test_rmse\", challenger_test_rmse)\n",
    "        mlflow.log_params({f\"final_{second_model_key}_{k}\": v for k, v in second_params.items()})\n",
    "        mlflow.set_tag(\"final_model_family\", second_model_key)\n",
    "        mlflow.set_tag(\"metric_selection\", \"rmse ASC (second best)\")\n",
    "        mlflow.set_tag(\"preprocessor_in_pipeline\", \"true\")\n",
    "\n",
    "        x_example = X_test.head(5)\n",
    "        y_example = second_pipe.predict(x_example)\n",
    "        sig2 = infer_signature(x_example, y_example)\n",
    "        mlflow.sklearn.log_model(\n",
    "            second_pipe,\n",
    "            artifact_path=\"model\",\n",
    "            signature=sig2,\n",
    "            input_example=x_example\n",
    "        )\n",
    "\n",
    "        # >>> : tambi√©n guardar el preprocesador del challenger en MLflow y LOCAL ./preprocesador/\n",
    "        fitted_preprocessor_chal = second_pipe.named_steps[\"prep\"]\n",
    "\n",
    "        # a) Artifact MLflow\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=fitted_preprocessor_chal,\n",
    "            artifact_path=\"preprocessor\"\n",
    "        )\n",
    "\n",
    "        # b) Guardado LOCAL\n",
    "        ts2 = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        local_save_dir2 = PREPROC_LOCAL_DIR / f\"{second_model_key}_preprocessor_{ts2}\"\n",
    "        mlflow.sklearn.save_model(sk_model=fitted_preprocessor_chal, path=str(local_save_dir2))\n",
    "        print(f\"üíæ Preprocesador (challenger) guardado localmente en: {local_save_dir2.resolve()}\")\n",
    "        # <<< \n",
    "\n",
    "        chal_run_id = chal_run.info.run_id\n",
    "        chal_run_uri = f\"runs:/{chal_run_id}/model\"\n",
    "        res2 = mlflow.register_model(model_uri=chal_run_uri, name=MODEL_NAME_REG)\n",
    "        challenger_version = res2.version\n",
    "\n",
    "# Aliases en UC (soportados)\n",
    "client.set_registered_model_alias(name=MODEL_NAME_REG, alias=\"champion\",   version=champ_version)\n",
    "if challenger_version is not None:\n",
    "    client.set_registered_model_alias(name=MODEL_NAME_REG, alias=\"challenger\", version=challenger_version)\n",
    "\n",
    "print(\"\\n‚úÖ Registro completo en Model Registry (Unity Catalog)\")\n",
    "print(f\"  Champion  -> {MODEL_NAME_REG}@champion (v{champ_version})\")\n",
    "if challenger_version is not None:\n",
    "    print(f\"  Challenger -> {MODEL_NAME_REG}@challenger (v{challenger_version})\")\n",
    "print(\"\\nExperimento MLflow:\", EXPERIMENT_NAME)\n",
    "print(\"M√©trica √∫nica de selecci√≥n: RMSE (menor es mejor)\")\n",
    "print(\"Target:\", TARGET)\n",
    "print(\"Features:\", FEATURES)\n",
    "print(\"Train shape:\", tuple(train_df.shape), \"| Test shape:\", tuple(test_df.shape))\n",
    "\n",
    "# -------------------------------\n",
    "# >>> Tabla comparativa de la m√©trica principal entre modelos\n",
    "# -------------------------------\n",
    "comparison_rows = []\n",
    "for _, r in results_df.iterrows():\n",
    "    comparison_rows.append({\n",
    "        \"model_key\": r[\"model_key\"],\n",
    "        \"split\": \"val\",\n",
    "        \"rmse\": float(r[\"val_rmse\"])\n",
    "    })\n",
    "if best_test_rmse is not None:\n",
    "    comparison_rows.append({\n",
    "        \"model_key\": best_model_key,\n",
    "        \"split\": \"test\",\n",
    "        \"rmse\": best_test_rmse\n",
    "    })\n",
    "if 'challenger_test_rmse' in locals() and challenger_test_rmse is not None:\n",
    "    comparison_rows.append({\n",
    "        \"model_key\": second_model_key,\n",
    "        \"split\": \"test\",\n",
    "        \"rmse\": challenger_test_rmse\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_rows).sort_values([\"split\", \"rmse\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== Tabla comparativa RMSE (menor es mejor) ===\")\n",
    "print(comparison_df)\n",
    "\n",
    "csv_path = Path(\"model_metric_comparison.csv\")\n",
    "comparison_df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nüìÑ Tabla comparativa guardada en: {csv_path.resolve()}\")\n",
    "\n",
    "set_mlflow()\n",
    "with mlflow.start_run(run_name=\"METRICS_COMPARISON\") as cmp_run:\n",
    "    mlflow.log_text(comparison_df.to_csv(index=False), \"model_metric_comparison.csv\")\n",
    "    mlflow.set_tag(\"note\", \"Comparativa de RMSE entre modelos (val/test).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a09b81e",
   "metadata": {},
   "source": [
    "# 2) üì¶ Datos y Data Readiness\n",
    "\n",
    "**Versionado y tama√±os (train/test)**  \n",
    "- Rutas: `../data/processed/train_posts_clean.csv` y `../data/processed/test_posts_clean.csv`.  \n",
    "- Tama√±os usados en entrenamiento/final: **Train (685, 11)** | **Test (172, 11)**.  \n",
    "- Integridad: en cada run se loggea `md5` y `shape` de ambos datasets como artifacts (`*_train_meta.json`, `*_test_meta.json`).\n",
    "\n",
    "**Target & m√©tricas**  \n",
    "- **Target:** `score_clipped` (recorta outliers v√≠a IQR para estabilizar la varianza).  \n",
    "- **M√©trica principal:** **RMSE** (menor es mejor).  \n",
    "- M√©trica reportada en **val** durante HPO y en **test** para el modelo final.\n",
    "\n",
    "**Selecci√≥n de variables (features)**  \n",
    "Se parte de un set curado por EDA y de ingenier√≠a ligera:  \n",
    "- Num√©ricas: `num_comments_capped`, `recency_days`, `dayofweek`, `title_len`, `selftext_len`, `is_self`, `month`  \n",
    "- Categ√≥ricas: `link_flair_text`, `subreddit`, `author`  \n",
    "*(el c√≥digo filtra autom√°ticamente por columnas presentes en el dataset).*\n",
    "\n",
    "**Prevenci√≥n de data leakage**  \n",
    "- Se **excluyen** columnas con fuga: `post_id`, `url`, `permalink`, `thumbnail`.  \n",
    "- El target usa `score_clipped` (no derivado de variables futuras).  \n",
    "- La evaluaci√≥n final se hace en **test** separado.\n",
    "\n",
    "**Tabla breve de features (tipo y raz√≥n)**\n",
    "\n",
    "| Feature              | Tipo      | Raz√≥n/hip√≥tesis de valor |\n",
    "|---|---|---|\n",
    "| `num_comments_capped` | Num√©rica  | Se√±al de interacci√≥n temprana; cap al p99 reduce var extrema. |\n",
    "| `recency_days`       | Num√©rica  | Efecto de frescura del post. |\n",
    "| `dayofweek`          | Num√©rica (entero) | Patrones de consumo por d√≠a. |\n",
    "| `month`              | Num√©rica (entero) | Estacionalidad y tendencias. |\n",
    "| `title_len`          | Num√©rica  | Longitud del t√≠tulo correlaciona con CTR/engagement. |\n",
    "| `selftext_len`       | Num√©rica  | Carga informativa del contenido. |\n",
    "| `is_self`            | Binaria   | Diferencia entre link-post y text-post. |\n",
    "| `link_flair_text`    | Categ√≥rica| Tema/contexto del post (moderaci√≥n/comunidad). |\n",
    "| `subreddit`          | Categ√≥rica| Efecto de comunidad. |\n",
    "| `author`             | Categ√≥rica| Efecto autor (historial/credibilidad). |\n",
    "\n",
    "---\n",
    "\n",
    "# 3) üß± Preprocesamiento (ColumnTransformer/Pipeline)\n",
    "\n",
    "**Definici√≥n**  \n",
    "- `ColumnTransformer` con:  \n",
    "  - **Num√©ricas:** `StandardScaler(with_mean=True, with_std=True)` sobre columnas num√©ricas.  \n",
    "  - **Categ√≥ricas:** `OneHotEncoder(handle_unknown=\"ignore\", min_frequency=5)` sobre `object`.\n",
    "\n",
    "**Integraci√≥n y versionado**  \n",
    "- El **preprocessor est√° integrado** en cada `Pipeline` (`(\"prep\", preprocessor) ‚Üí (\"model\", estimador)`), por lo que **viaja junto al modelo**.  \n",
    "- Adem√°s, se **versiona por separado**:  \n",
    "  - Se loggea como **artifact MLflow** en `preprocessor/`.  \n",
    "  - Se guarda **local** en `../preprocesador/<modelo>_preprocessor_<timestamp>/` (directorio con `MLmodel` + pickles).\n",
    "\n",
    "**Reproducibilidad**  \n",
    "- Semilla global `SEED=42` para split y modelos; `Hyperopt` con `default_rng(SEED)`.  \n",
    "- Tracking determin√≠stico: se registran rutas, shapes, `md5`, lista de `FEATURES` y `TARGET` en `run_context.txt`.\n",
    "\n",
    "**Evidencia m√≠nima**  \n",
    "- En los runs `FINAL_*` aparecen artifacts `model/` (pipeline completo) y `preprocessor/` (solo transformador).  \n",
    "- Mensajes de consola confirman los guardados locales en `../preprocesador/...`.\n",
    "\n",
    "---\n",
    "\n",
    "# 4) üß™ Experimentos de Modelado (‚â•3 modelos)\n",
    "\n",
    "**Familias y HPO**  \n",
    "- Modelos: **ElasticNet**, **RandomForestRegressor**, **XGBRegressor**.  \n",
    "- Para cada familia:  \n",
    "  - `HPO_<modelo>` con **runs anidados** (`nested=True`).  \n",
    "  - Se loggean **par√°metros**, **RMSE (val)**, **snapshots** (`<modelo>_best_snapshot`) y **metadatos de datasets**.  \n",
    "\n",
    "**Evidencia (capturas MLflow)**  \n",
    "- Se observan los runs `HPO_elasticnet`, `HPO_random_forest`, `HPO_xgboost` y sus `*_trial`.  \n",
    "- En la tabla de experimentos se comparan m√©tricas y par√°metros por run.\n",
    "\n",
    "---\n",
    "\n",
    "# 5) üéØ Tuning con Hyperopt + MLflow (Databricks)\n",
    "\n",
    "- **Espacios de b√∫squeda** definidos por familia (p. ej., `n_estimators`, `max_depth`, `l1_ratio`, etc.).  \n",
    "- **Objetivo:** minimizar **RMSE** en `val`.  \n",
    "- **Estructura de runs:**  \n",
    "  - `IMEDIA_EMI_AllModels` (parent) ‚Üí `HPO_<modelo>` (parent por familia) ‚Üí `<modelo>_trial` (runs hijos).  \n",
    "- **Artifacts clave:** `run_context.txt`, snapshots de los mejores pipelines por familia y metadatos de datasets.\n",
    "\n",
    "**Evidencia m√≠nima**  \n",
    "- Pantalla de MLflow muestra **runs anidados** y **par√°metros**; se ve la **comparativa** de RMSE por familia.\n",
    "\n",
    "---\n",
    "\n",
    "# 6) üèÜ Selecci√≥n del Mejor Modelo\n",
    "\n",
    "**Criterio**  \n",
    "- Orden expl√≠cito por **RMSE (ascendente)** sobre la validaci√≥n: `results_df.sort_values(\"val_rmse\")`.\n",
    "\n",
    "**Resultado**  \n",
    "- Ranking en `val`: **Random Forest (210.75)** < ElasticNet (216.74) < XGBoost (220.67).  \n",
    "- Se reentrena el **mejor** con todo el train y se eval√∫a en **test**.\n",
    "\n",
    "**Evidencia de ‚Äúmejor en contexto‚Äù**  \n",
    "- En **test**, **Random Forest** consigue **RMSE ‚âà 171.82**, muy por debajo del segundo (**ElasticNet ‚âà 248.97**).  \n",
    "- Justificaci√≥n breve: RF captura no linealidades e interacciones t√≠picas entre se√±ales de interacci√≥n (`num_comments_capped`) y contexto (`subreddit`, `flair`), mejor que modelos lineales; XGB qued√≥ atr√°s con este tama√±o y sparsidad.\n",
    "\n",
    "**Identificador de best run**  \n",
    "- Run final: `FINAL_random_forest_on_full_train` (v√©ase MLflow UI en el experimento).  \n",
    "- Tabla comparativa exportada: `model_metric_comparison.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "# 7) üóÇÔ∏è Registro en el Model Registry\n",
    "\n",
    "**Nomenclatura**  \n",
    "- Modelo en UC: **`workspace.default/EMI_imedia_model`**.\n",
    "\n",
    "**Qu√© se registra**  \n",
    "- **Pipeline completo** (incluye `preprocessor` dentro del `Pipeline`).  \n",
    "- **Alias:**  \n",
    "  - `@champion` ‚Üí **Version 3** (Random Forest, **test_rmse ‚âà 171.82**).  \n",
    "  - `@challenger` ‚Üí **Version 4** (ElasticNet, **test_rmse ‚âà 248.97**).\n",
    "\n",
    "**Documentaci√≥n del modelo**  \n",
    "- En `model_description.json` se incluyen: datos, m√©trica, fecha, features, seeds, y changelog.  \n",
    "- **Preprocessor** adicionalmente guardado como artifact `preprocessor/` y **local** en `../preprocesador/‚Ä¶`.\n",
    "\n",
    "**Evidencia m√≠nima**  \n",
    "- Capturas de **Catalog Explorer** muestran `emi_imedia_model` con **Version 3 (@champion)** y **Version 4 (@challenger)**.  \n",
    "- En el listado del experimento se visualizan `FINAL_*` y la **m√©trica de test** de cada final.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Tabla comparativa (RMSE ‚Üì)\n",
    "\n",
    "| model_key     | split | RMSE |\n",
    "|---|---:|---:|\n",
    "| random_forest | test | **171.82** |\n",
    "| elasticnet    | test | 248.97 |\n",
    "| random_forest | val  | 210.75 |\n",
    "| elasticnet    | val  | 216.74 |\n",
    "| xgboost       | val  | 220.67 |\n",
    "\n",
    "> **Conclusi√≥n:** Se promueve **`workspace.default/EMI_imedia_model@champion (v3)`**. El **preprocessor** queda **dentro** del pipeline registrado y **aparte** como artifact + copia **local** en `../preprocesador/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "560ed3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Chunk 1 ¬∑ Setup + Data + MLflow + dirs para artefactos\n",
    "# ============================\n",
    "import os, json, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Transformers / Sentence-Transformers\n",
    "import torch\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# -----------------------\n",
    "# Configuraci√≥n\n",
    "# -----------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DATA_PROCESSED = Path(\"../data/processed\")\n",
    "\n",
    "# Carpetas de artefactos\n",
    "EMBEDDINGS_DIR = Path(\"../embeddings\")\n",
    "PREPROC_DIR = Path(\"../preprocesador\")\n",
    "EMBEDDINGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PREPROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "EXPERIMENT_NAME = \"/Users/marianasgg19@gmail.com/EMI/imedia/Sentiment_BERT_MLP\"\n",
    "DEEP_MODEL_NAME = \"workspace.default.imedia_sentiment_mlp_transformer\"\n",
    "\n",
    "# -----------------------\n",
    "# Carga de datos\n",
    "# -----------------------\n",
    "train_df = pd.read_parquet(DATA_PROCESSED / \"sentiment_train.parquet\")\n",
    "val_df   = pd.read_parquet(DATA_PROCESSED / \"sentiment_val.parquet\")\n",
    "test_df  = pd.read_parquet(DATA_PROCESSED / \"sentiment_test.parquet\")\n",
    "\n",
    "FEATURE_COL = \"clean_text\"\n",
    "TARGET_COL  = \"sentiment\"\n",
    "\n",
    "X_train = train_df[FEATURE_COL].astype(str).tolist()\n",
    "y_train = train_df[TARGET_COL].astype(int).values\n",
    "\n",
    "X_val   = val_df[FEATURE_COL].astype(str).tolist()\n",
    "y_val   = val_df[TARGET_COL].astype(int).values\n",
    "\n",
    "X_test  = test_df[FEATURE_COL].astype(str).tolist()\n",
    "y_test  = test_df[TARGET_COL].astype(int).values\n",
    "\n",
    "# -----------------------\n",
    "# MLflow tracking\n",
    "# -----------------------\n",
    "def _resolve_tracking_uri():\n",
    "    load_dotenv(override=True)\n",
    "    env_uri  = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "    profile  = os.getenv(\"DATABRICKS_CONFIG_PROFILE\")\n",
    "    host     = os.getenv(\"DATABRICKS_HOST\")\n",
    "    token    = os.getenv(\"DATABRICKS_TOKEN\")\n",
    "\n",
    "    if env_uri: return env_uri\n",
    "    if profile: return f\"databricks://{profile}\"\n",
    "    if host and token: return \"databricks\"\n",
    "\n",
    "    local = Path.cwd() / \"mlruns\"\n",
    "    local.mkdir(exist_ok=True)\n",
    "    return f\"file://{local}\"\n",
    "\n",
    "def set_mlflow():\n",
    "    mlflow.set_tracking_uri(_resolve_tracking_uri())\n",
    "    client = MlflowClient()\n",
    "    exp = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if exp is None:\n",
    "        mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "set_mlflow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df01071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run baseline_nlptown/bert-base-multilingual-uncased-sentiment_NTBK at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/1690980704956355/runs/130bfa8b8c2d4ec18e57f1639c9d4829\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/1690980704956355\n",
      "üèÉ View run baseline_distilbert-base-uncased-finetuned-sst-2-english_NTBK at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/1690980704956355/runs/8d81399bad86477c8f0b74a50e367d59\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/1690980704956355\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Chunk 2 ¬∑ Baselines BERT (2 modelos) + Preprocesador placeholder NTBK\n",
    "# ============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -----------------------\n",
    "# BERT #1\n",
    "# -----------------------\n",
    "BERT1_NAME = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tok_bert1 = AutoTokenizer.from_pretrained(BERT1_NAME)\n",
    "mdl_bert1 = AutoModelForSequenceClassification.from_pretrained(BERT1_NAME).to(device)\n",
    "\n",
    "def predict_bert1(texts):\n",
    "    preds = []\n",
    "    for t in texts:\n",
    "        inputs = tok_bert1(t, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = mdl_bert1(**inputs).logits\n",
    "        probs = softmax(logits.cpu().numpy(), axis=1)\n",
    "        idx = np.argmax(probs, axis=1)[0]\n",
    "        preds.append(0 if idx <= 2 else 1)\n",
    "    return np.array(preds)\n",
    "\n",
    "# -----------------------\n",
    "# BERT #2\n",
    "# -----------------------\n",
    "BERT2_NAME = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tok_bert2 = AutoTokenizer.from_pretrained(BERT2_NAME)\n",
    "mdl_bert2 = AutoModelForSequenceClassification.from_pretrained(BERT2_NAME).to(device)\n",
    "\n",
    "def predict_bert2(texts):\n",
    "    preds = []\n",
    "    for t in texts:\n",
    "        inputs = tok_bert2(t, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = mdl_bert2(**inputs).logits\n",
    "        probs = softmax(logits.cpu().numpy(), axis=1)\n",
    "        preds.append(int(np.argmax(probs, axis=1)[0]))\n",
    "    return np.array(preds)\n",
    "\n",
    "# -----------------------\n",
    "# Funci√≥n de evaluaci√≥n MLflow\n",
    "# -----------------------\n",
    "def eval_and_log_bert(model_name, predict_fn):\n",
    "    with mlflow.start_run(run_name=f\"baseline_{model_name}_NTBK\") as run:\n",
    "        y_val_pred  = predict_fn(X_val)\n",
    "        y_test_pred = predict_fn(X_test)\n",
    "\n",
    "        mlflow.log_param(\"model_family\", \"bert_pretrained_baseline\")\n",
    "        mlflow.log_param(\"hf_model_name\", model_name)\n",
    "\n",
    "        mlflow.log_metric(\"val_accuracy\",  accuracy_score(y_val,  y_val_pred))\n",
    "        mlflow.log_metric(\"val_f1\",        f1_score(y_val, y_val_pred))\n",
    "        mlflow.log_metric(\"test_accuracy\", accuracy_score(y_test, y_test_pred))\n",
    "        mlflow.log_metric(\"test_f1\",       f1_score(y_test, y_test_pred))\n",
    "\n",
    "        # -----------------------\n",
    "        # Preprocesador NTBK guardado\n",
    "        # -----------------------\n",
    "        preproc_path = PREPROC_DIR / f\"preprocessor_{model_name.replace('/','_')}_NTBK\"\n",
    "        preproc_path.mkdir(parents=True, exist_ok=True)\n",
    "        (preproc_path / \"placeholder.txt\").write_text(\"No sklearn preprocessor (BERT model). NTBK\")\n",
    "\n",
    "        mlflow.log_artifact(preproc_path)\n",
    "\n",
    "# Ejecutar\n",
    "eval_and_log_bert(BERT1_NAME, predict_bert1)\n",
    "eval_and_log_bert(BERT2_NAME, predict_bert2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be1156d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4ae846fd4642c28e5338734ed8dd92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8e947fe4134969be870f68ca23d8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c0d44f68bb4700b472f026d5bb7d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.67165255\n",
      "Iteration 2, loss = 0.62857594\n",
      "Iteration 3, loss = 0.59494416\n",
      "Iteration 4, loss = 0.57511548\n",
      "Iteration 5, loss = 0.55955338\n",
      "Iteration 6, loss = 0.54681950\n",
      "Iteration 7, loss = 0.53513976\n",
      "Iteration 8, loss = 0.52429407\n",
      "Iteration 9, loss = 0.51365622\n",
      "Iteration 10, loss = 0.50370759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/02 02:42:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025/12/02 02:42:31 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Registered model 'workspace.default.imedia_sentiment_mlp_transformer' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551a2e0902bd4bd397c9f42b6963baae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'workspace.default.imedia_sentiment_mlp_transformer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run mlp_transformer_embeddings_NTBK at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/1690980704956355/runs/a45423705a66491f885b254b8c4e6163\n",
      "üß™ View experiment at: https://dbc-5922e233-b716.cloud.databricks.com/ml/experiments/1690980704956355\n",
      "Embeddings guardados en: ../embeddings/sentence-transformers_all-MiniLM-L6-v2_embeddings_NTBK_20251202T084227.npy\n",
      "Preprocesador NTBK guardado en: ../preprocesador/preprocessor_transformer_MLP_NTBK_20251202T084227\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Chunk 3 ¬∑ SentenceTransformer embeddings + MLPClassifier + Artefactos NTBK\n",
    "# ============================\n",
    "\n",
    "ST_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "st_model = SentenceTransformer(ST_MODEL_NAME)\n",
    "\n",
    "def embed_texts(model, texts, batch_size=32):\n",
    "    return model.encode(\n",
    "        list(texts),\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True,\n",
    "    )\n",
    "\n",
    "# Generar embeddings\n",
    "X_train_emb = embed_texts(st_model, X_train)\n",
    "X_val_emb   = embed_texts(st_model, X_val)\n",
    "X_test_emb  = embed_texts(st_model, X_test)\n",
    "\n",
    "# -----------------------\n",
    "# Guardar embeddings con sufijo NTBK\n",
    "# -----------------------\n",
    "timestamp = datetime.utcnow().strftime(\"%Y%m%dT%H%M%S\")\n",
    "emb_file = EMBEDDINGS_DIR / f\"{ST_MODEL_NAME.replace('/','_')}_embeddings_NTBK_{timestamp}.npy\"\n",
    "np.save(emb_file, np.vstack([X_train_emb, X_val_emb, X_test_emb]))\n",
    "\n",
    "metadata = {\n",
    "    \"model\": ST_MODEL_NAME,\n",
    "    \"sizes\": {\"train\": len(y_train), \"val\": len(y_val), \"test\": len(y_test)},\n",
    "    \"shape\": X_train_emb.shape,\n",
    "    \"timestamp\": timestamp\n",
    "}\n",
    "meta_file = EMBEDDINGS_DIR / f\"{ST_MODEL_NAME.replace('/','_')}_metadata_NTBK_{timestamp}.json\"\n",
    "pd.Series(metadata).to_json(meta_file)\n",
    "\n",
    "# -----------------------\n",
    "# Entrenar MLP\n",
    "# -----------------------\n",
    "mlp_clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(256,),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    batch_size=256,\n",
    "    learning_rate_init=1e-3,\n",
    "    max_iter=10,\n",
    "    random_state=SEED,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name=\"mlp_transformer_embeddings_NTBK\") as run:\n",
    "    mlp_clf.fit(X_train_emb, y_train)\n",
    "\n",
    "    y_val_pred  = mlp_clf.predict(X_val_emb)\n",
    "    y_test_pred = mlp_clf.predict(X_test_emb)\n",
    "\n",
    "    mlflow.log_metric(\"val_accuracy\",  accuracy_score(y_val, y_val_pred))\n",
    "    mlflow.log_metric(\"val_f1\",        f1_score(y_val,  y_val_pred))\n",
    "    mlflow.log_metric(\"test_accuracy\", accuracy_score(y_test, y_test_pred))\n",
    "    mlflow.log_metric(\"test_f1\",       f1_score(y_test, y_test_pred))\n",
    "\n",
    "    # -----------------------\n",
    "    # Guardar preprocesador NTBK\n",
    "    # -----------------------\n",
    "    preproc_path = PREPROC_DIR / f\"preprocessor_transformer_MLP_NTBK_{timestamp}\"\n",
    "    preproc_path.mkdir(parents=True, exist_ok=True)\n",
    "    (preproc_path / \"preprocessor_info.txt\").write_text(\n",
    "        \"No sklearn preprocessor. Uses SentenceTransformer embeddings. NTBK\"\n",
    "    )\n",
    "    mlflow.log_artifact(preproc_path)\n",
    "\n",
    "    # Registrar MLP en MLflow\n",
    "    example_input = X_train_emb[:50]\n",
    "    signature = infer_signature(example_input, mlp_clf.predict(example_input))\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=mlp_clf,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=DEEP_MODEL_NAME,\n",
    "        signature=signature,\n",
    "        input_example=example_input[:5],\n",
    "    )\n",
    "\n",
    "print(\"Embeddings guardados en:\", emb_file)\n",
    "print(\"Preprocesador NTBK guardado en:\", preproc_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9720c8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "EXPLICAR POR QUE ESTOS MODELOS Y COMO LO HACE CADA UNO Y COMO SE VALIDA Y LA PARTE DE POR QUE LA METRICA ES F1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imedia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
